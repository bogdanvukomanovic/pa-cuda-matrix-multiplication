{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[PA]_Projekat_III.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMZm0YTUOnR3"
      },
      "source": [
        "Koristeći PyCuda okurženje napisati CUDA program za (matrično) množenje matrica.\n",
        "\n",
        "1. Program koji vrši množenja matrica malih dimenzija (množenje se može izvršiti upotrebom jednom bloka niti).\n",
        "2. Program koji vrši množenje matrica većih dimenzija, upotrebom većeg broja CUDA blokova.\n",
        "3. Ubrzati rešenje iz stavke 2 upotrebom deljene memorije (tako da niti jednog bloka prvo dovuku deo podataka u deljenu memeorju, a potom sve čitaju iz deljene memorije)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79GoGcX7xbpl"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_-r2A5Kx0tG"
      },
      "source": [
        "import pycuda.driver as cuda\r\n",
        "import pycuda.autoinit\r\n",
        "from pycuda.compiler import SourceModule\r\n",
        "import numpy as np\r\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4KHgP9955eS"
      },
      "source": [
        "1. Program koji vrši množenja matrica malih dimenzija (množenje se može izvršiti upotrebom jednom bloka niti)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZQuEf7PQH8R"
      },
      "source": [
        "mod = SourceModule(\r\n",
        "    \"\"\"\r\n",
        "    __constant__ unsigned int uiRowLength, uiColumnLength;\r\n",
        "\r\n",
        "    __global__ void vSingleBlockMatMul( int* piA, int* piB, int* piProduct )\r\n",
        "    {\r\n",
        "        float fSum = 0.0;\r\n",
        "\r\n",
        "        for( int i = 0; i < uiRowLength; i++ )\r\n",
        "        {\r\n",
        "            fSum += piA[ threadIdx.x * uiRowLength + i ] * piB[ threadIdx.y + uiColumnLength * i ];\r\n",
        "        }\r\n",
        "        piProduct[ threadIdx.x * uiColumnLength + threadIdx.y ] = fSum;\r\n",
        "    }\r\n",
        "         \r\n",
        "    \"\"\"\r\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62CL3mikgXRw"
      },
      "source": [
        "a = np.random.randn( 100, 250 ).astype( dtype = np.int32 )\r\n",
        "b = np.random.randn( 250, 10 ).astype( dtype = np.int32 )\r\n",
        "\r\n",
        "result = np.matmul( a, b )\r\n",
        "\r\n",
        "c = np.zeros_like( result )\r\n",
        "\r\n",
        "a_gpu = cuda.mem_alloc( a.nbytes )\r\n",
        "b_gpu = cuda.mem_alloc( b.nbytes )\r\n",
        "c_gpu = cuda.mem_alloc( c.nbytes )\r\n",
        "\r\n",
        "cuda.memcpy_htod( a_gpu, a )\r\n",
        "cuda.memcpy_htod( b_gpu, b )\r\n",
        "cuda.memcpy_htod( c_gpu, c )\r\n",
        "\r\n",
        "uiRowLength_gpu = mod.get_global( 'uiRowLength' )       # Index 0 means address, 1 is data length.\r\n",
        "cuda.memcpy_htod( uiRowLength_gpu[0], np.uintc( a.shape[1] ) )\r\n",
        "\r\n",
        "uiColumnLength_gpu = mod.get_global( 'uiColumnLength' ) # Index 0 means address, 1 is data length.\r\n",
        "cuda.memcpy_htod( uiColumnLength_gpu[0], np.uintc( b.shape[1] ) )\r\n",
        "\r\n",
        "gpu_vSingleBlockMatMul = mod.get_function( 'vSingleBlockMatMul' )\r\n",
        "gpu_vSingleBlockMatMul( a_gpu, b_gpu, c_gpu, block = ( a.shape[0], b.shape[1], 1 ), grid = ( 1, 1, 1 ) )\r\n",
        "\r\n",
        "cuda.memcpy_dtoh( c, c_gpu )\r\n",
        "\r\n",
        "print('Correct: ', ( c == result ).all() )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m18KV4bL6DHd"
      },
      "source": [
        "2. Program koji vrši množenje matrica većih dimenzija, upotrebom većeg broja CUDA blokova."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-g_hHLgjmks"
      },
      "source": [
        "mod = SourceModule(\r\n",
        "    \"\"\"\r\n",
        "    __constant__ unsigned int uiRowLength, uiColumnLength, uiOutputMatrixWidth, uiOutputMatrixHeight;\r\n",
        "\r\n",
        "    __global__ void vMultiBlockMatMul( int* piA, int* piB, int* piProduct )\r\n",
        "    {\r\n",
        "\r\n",
        "        const unsigned int uiProductIndex = threadIdx.x + blockDim.x * blockIdx.x + threadIdx.y * uiOutputMatrixWidth + blockDim.y * blockIdx.y * uiOutputMatrixHeight;\r\n",
        "        const unsigned int uiRowIndexA = uiProductIndex / uiOutputMatrixWidth;\r\n",
        "        const unsigned int uiColumnIndexB = uiProductIndex % uiOutputMatrixWidth;\r\n",
        "\r\n",
        "        float fSum = 0.0;\r\n",
        "\r\n",
        "        if ( uiProductIndex <= uiOutputMatrixWidth * uiOutputMatrixHeight )\r\n",
        "        {\r\n",
        "            for( int i = 0; i < uiRowLength; i++ )\r\n",
        "            {\r\n",
        "                fSum += piA[ uiRowIndexA * uiRowLength + i ] * piB[ uiColumnIndexB + i * uiOutputMatrixWidth ];\r\n",
        "            }\r\n",
        "            \r\n",
        "            piProduct[ uiProductIndex ] = fSum;\r\n",
        "        }\r\n",
        "    }\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kex0ZSPv6MC5"
      },
      "source": [
        "a = np.random.randn( 1000, 1000 ).astype( dtype = np.int32 )\r\n",
        "b = np.random.randn( 1000, 1000 ).astype( dtype = np.int32 )\r\n",
        "\r\n",
        "result = np.matmul( a, b )\r\n",
        "\r\n",
        "c = np.zeros_like( result )\r\n",
        "\r\n",
        "a_gpu = cuda.mem_alloc( a.nbytes )\r\n",
        "b_gpu = cuda.mem_alloc( b.nbytes )\r\n",
        "c_gpu = cuda.mem_alloc( c.nbytes )\r\n",
        "\r\n",
        "cuda.memcpy_htod( a_gpu, a )\r\n",
        "cuda.memcpy_htod( b_gpu, b )\r\n",
        "cuda.memcpy_htod( c_gpu, c )\r\n",
        "\r\n",
        "uiRowLength_gpu = mod.get_global( 'uiRowLength' )                   # Index 0 means address, 1 is data length.\r\n",
        "cuda.memcpy_htod( uiRowLength_gpu[0], np.uintc( a.shape[1] ) )\r\n",
        "\r\n",
        "uiColumnLength_gpu = mod.get_global( 'uiColumnLength' )             # Index 0 means address, 1 is data length.\r\n",
        "cuda.memcpy_htod( uiColumnLength_gpu[0], np.uintc( b.shape[1] ) )\r\n",
        "\r\n",
        "uiOutputMatrixWidth = mod.get_global( 'uiOutputMatrixWidth' )       # Index 0 means address, 1 is data length.\r\n",
        "cuda.memcpy_htod( uiOutputMatrixWidth[0], np.uintc( b.shape[1] ) )\r\n",
        "\r\n",
        "uiOutputMatrixHeight = mod.get_global( 'uiOutputMatrixHeight' )     # Index 0 means address, 1 is data length.\r\n",
        "cuda.memcpy_htod( uiOutputMatrixHeight[0], np.uintc( a.shape[0] ) )\r\n",
        "\r\n",
        "\r\n",
        "gpu_vMultiBlockMatMul = mod.get_function( 'vMultiBlockMatMul' )\r\n",
        "gpu_vMultiBlockMatMul( a_gpu, b_gpu, c_gpu, block = ( 32, 32, 1 ), grid = ( math.ceil( a.shape[1] / 32 ), math.ceil( a.shape[0] / 32 ), 1 ) )\r\n",
        "\r\n",
        "cuda.memcpy_dtoh( c, c_gpu )\r\n",
        "\r\n",
        "print('Correct: ', ( c == result ).all() )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoVR05rN6MYc"
      },
      "source": [
        "3. Ubrzati rešenje iz stavke 2 upotrebom deljene memorije (tako da niti jednog bloka prvo dovuku deo podataka u deljenu memeorju, a potom sve čitaju iz deljene memorije)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONatqF0pjnl-"
      },
      "source": [
        "mod = SourceModule(\r\n",
        "    \"\"\"\r\n",
        "    __constant__ unsigned int uiRowLength, uiColumnLength, uiOutputMatrixWidth, uiOutputMatrixHeight;\r\n",
        "\r\n",
        "    __global__ void vMultiBlockMatMulShared( int* piA, int* piB, int* piProduct )\r\n",
        "    {\r\n",
        "        const unsigned int uiGridHeight = gridDim.y * blockDim.y;\r\n",
        "        const unsigned int uiGridWidth = gridDim.x * blockDim.x;\r\n",
        "\r\n",
        "        const unsigned int uiCudaIndex = threadIdx.x + blockDim.x * blockIdx.x + threadIdx.y * uiGridWidth + blockDim.y * blockIdx.y * uiGridHeight;\r\n",
        "\r\n",
        "        const unsigned int uiRowIndexA = uiCudaIndex / ( uiGridWidth );\r\n",
        "        const unsigned int uiColumnIndexB = uiCudaIndex % ( uiGridWidth );\r\n",
        "\r\n",
        "        if ( uiRowIndexA >= uiOutputMatrixHeight || uiColumnIndexB >= uiOutputMatrixWidth ) \r\n",
        "        {\r\n",
        "            return;\r\n",
        "        }\r\n",
        "\r\n",
        "        __shared__ int piSubA[ 100 * 32 ];\r\n",
        "        __shared__ int piSubB[ 100 * 32 ];\r\n",
        "\r\n",
        "        if( threadIdx.x == 0 )\r\n",
        "        {\r\n",
        "            for( int i = 0; i < uiRowLength; i++ )\r\n",
        "            {   \r\n",
        "                piSubA[ threadIdx.y * uiRowLength + i ] = piA[ uiRowIndexA * uiRowLength + i ];\r\n",
        "            }   \r\n",
        "        }\r\n",
        "\r\n",
        "        if( threadIdx.y == 0 )\r\n",
        "        {\r\n",
        "            for( int i = 0; i < uiRowLength; i++ )\r\n",
        "            {\r\n",
        "                piSubB[ i * blockDim.x + threadIdx.x ] = piB[ i * uiOutputMatrixWidth + uiColumnIndexB ];\r\n",
        "            }   \r\n",
        "        }        \r\n",
        "\r\n",
        "        __syncthreads();\r\n",
        "        \r\n",
        "        int iSum = 0;\r\n",
        "\r\n",
        "        for( int i = 0; i < uiRowLength; i++ )\r\n",
        "        {\r\n",
        "            iSum += piSubA[ threadIdx.y * uiRowLength + i ] * piSubB[ threadIdx.x + blockDim.x * i ];           \r\n",
        "        }\r\n",
        "        \r\n",
        "        piProduct[ uiRowIndexA * uiOutputMatrixWidth + uiColumnIndexB ] = iSum;\r\n",
        "\r\n",
        "    }\r\n",
        "   \"\"\"\r\n",
        "   \r\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYzPNDMd6UCP"
      },
      "source": [
        "a = np.random.randn( 86, 10 ).astype( dtype = np.int32 )\r\n",
        "b = np.random.randn( 10, 14 ).astype( dtype = np.int32 )\r\n",
        "result = np.matmul( a, b )\r\n",
        "\r\n",
        "c = np.ones_like( result )\r\n",
        "\r\n",
        "a_gpu = cuda.mem_alloc( a.nbytes )\r\n",
        "b_gpu = cuda.mem_alloc( b.nbytes )\r\n",
        "c_gpu = cuda.mem_alloc( c.nbytes )\r\n",
        "\r\n",
        "cuda.memcpy_htod( a_gpu, a )\r\n",
        "cuda.memcpy_htod( b_gpu, b )\r\n",
        "cuda.memcpy_htod( c_gpu, c )\r\n",
        "\r\n",
        "uiRowLength_gpu = mod.get_global( 'uiRowLength' )                   # Index 0 means address, 1 is data length.\r\n",
        "cuda.memcpy_htod( uiRowLength_gpu[0], np.uintc( a.shape[1] ) )\r\n",
        "\r\n",
        "uiColumnLength_gpu = mod.get_global( 'uiColumnLength' )             # Index 0 means address, 1 is data length.\r\n",
        "cuda.memcpy_htod( uiColumnLength_gpu[0], np.uintc( b.shape[1] ) )\r\n",
        "\r\n",
        "uiOutputMatrixWidth = mod.get_global( 'uiOutputMatrixWidth' )       # Index 0 means address, 1 is data length.\r\n",
        "cuda.memcpy_htod( uiOutputMatrixWidth[0], np.uintc( b.shape[1] ) )\r\n",
        "\r\n",
        "uiOutputMatrixHeight = mod.get_global( 'uiOutputMatrixHeight' )     # Index 0 means address, 1 is data length.\r\n",
        "cuda.memcpy_htod( uiOutputMatrixHeight[0], np.uintc( a.shape[0] ) )\r\n",
        "\r\n",
        "block_size = 32\r\n",
        "\r\n",
        "gpu_vMultiBlockMatMulShared = mod.get_function( 'vMultiBlockMatMulShared' )\r\n",
        "\r\n",
        "grid_dim = max( math.ceil( a.shape[0] / block_size ), math.ceil( b.shape[1] / block_size ) )\r\n",
        "gpu_vMultiBlockMatMulShared( a_gpu, b_gpu, c_gpu, block = ( block_size, block_size, 1 ), grid = ( grid_dim, grid_dim, 1 ) )\r\n",
        "\r\n",
        "cuda.memcpy_dtoh( c, c_gpu )\r\n",
        "\r\n",
        "print('Correct: ', ( c == result ).all() )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}